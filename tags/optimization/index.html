<!DOCTYPE html>
<html lang="en"
  dir="ltr">

<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">








    






<link rel="icon" type="image/ico" href="https://liuyiyuelily.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://liuyiyuelily.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://liuyiyuelily.github.io/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="192x192" href="https://liuyiyuelily.github.io/android-chrome-192x192.png">
<link rel="apple-touch-icon" sizes="180x180" href="https://liuyiyuelily.github.io/apple-touch-icon.png">

<link rel="alternate" type="application/rss+xml" href="https://liuyiyuelily.github.io/tags/optimization/index.xml" title="Yiyue Liu Blog">
<meta name="description" content=""/>



<title>
    
    Optimization | Yiyue Liu Blog
    
</title>

<link rel="canonical" href="https://liuyiyuelily.github.io/tags/optimization/"/>

<meta property="og:url" content="https://liuyiyuelily.github.io/tags/optimization/">
  <meta property="og:site_name" content="Yiyue Liu Blog">
  <meta property="og:title" content="Optimization">
  <meta property="og:description" content="A Tech Blog">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="website">












<link rel="stylesheet" href="/assets/combined.min.ec1cb1295de3dde3caaea524689a83d88207da8aff8cc7829338c2a88f36f956.css" media="all">




      <script async src="https://www.googletagmanager.com/gtag/js?id=G-xxxxxxxxx"></script>
      <script>
        var doNotTrack = false;
        if ( true ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-xxxxxxxxx');
        }
      </script>











    




  
  <link rel="stylesheet" href="/css/custom.css">
</head>







<body class="auto">

  <div class="content">
    <header style="position: relative;">
      

<div class="header">

    

    <h1 class="header-title">
        <a href="https://liuyiyuelily.github.io/">Yiyue Liu Blog</a>
    </h1>

    <div class="header-menu">
        
        

        
        
        
        <p class="small ">
            <a href="/" >
                /Home
            </a>
        </p>
        
        
        <p class="small ">
            <a href="/archives/" >
                /Archive
            </a>
        </p>
        
        
        <p class="small ">
            <a href="/software_engineering/" >
                /Software Engineering
            </a>
        </p>
        
        
        <p class="small ">
            <a href="/llm/" >
                /LLM
            </a>
        </p>
        
        
    </div>

    

</div>


      
      <div class="lang-switch">
        
          

          
            <span class="active">English</span>
          

          
            |
          
        
          

          
            

            
            

            
            
              
                
              
                
                  
                
              
            

            <a href="/zh/">中文</a>
          

          
        
      </div>
      

    </header>

    <main class="main">
      

<div class="list-container">

    <div class="breadcrumbs"><a href="/">Home</a><span class="breadcrumbs-separator">/</span><a href="/tags/">Tags</a><span class="breadcrumbs-separator">/</span>
        <a href="/tags/optimization/">Optimization</a></div>

    <h1>Optimization</h1>
    

    

    
    
    
    

    

    

    
    <div class="post-line">

    

    
        <p class="line-date">19 Feb 2026 </p>
    

    <div>
        <p class="line-title">
            <a href="/llm/cpu_gpu_optimizations_4_torch/">
                [4/4] CPU-GPU Optimization: PyTorch
            </a>
        </p>

        
        
        
        
        
        
        
            
        
        
            
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
        
        
        <p class="line-summary">This is the final post in the “CPU‑GPU Optimization” series. Here we use kernel‑ and CUDA‑level techniques from earlier posts to explain asynchronous execution in PyTorch and how to reduce CPU‑GPU synchronization costs. Asynchronous Execution When a PyTorch program runs on the CPU, each line executes in program order....</p>
        
    </div>
</div>

    

    

    
    <div class="post-line">

    

    
        <p class="line-date">6 Feb 2026 </p>
    

    <div>
        <p class="line-title">
            <a href="/llm/cpu_gpu_optimizations_3_cuda_stream/">
                [3/4] CPU-GPU Optimization: CUDA Stream and Async Memcpy
            </a>
        </p>

        
        
        
        
        
        
        
            
        
        
            
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
        
        
        <p class="line-summary">In this blog, we will discuss techniques to squeeze the memcpy &amp;ldquo;bubbles&amp;rdquo; with kernel executions. We first discuss CUDA streams which allows operations to run concurrently. Then we discuss asynchronous memcpys to overlap data transfers with kernels....</p>
        
    </div>
</div>

    

    

    
    <div class="post-line">

    

    
        <p class="line-date">5 Feb 2026 </p>
    

    <div>
        <p class="line-title">
            <a href="/llm/cpu_gpu_optimizations_2_cuda_memcpy/">
                [2/4] CPU-GPU Optimization: CUDA Memory Allocation and Memcpy
            </a>
        </p>

        
        
        
        
        
        
        
            
        
        
            
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
        
        
        <p class="line-summary">This is the second blog of the &amp;ldquo;CPU-GPU Optimization&amp;rdquo; series. Using the foundations built from the previous blog, we will discuss 4 types of memory allocation and transfer methods in CUDA. 1....</p>
        
    </div>
</div>

    

    

    
    <div class="post-line">

    

    
        <p class="line-date">25 Jan 2026 </p>
    

    <div>
        <p class="line-title">
            <a href="/llm/cpu_gpu_optimizations_1_kernel/">
                [1/4] CPU-GPU Optimization: Pinned Memory in Linux Kernel
            </a>
        </p>

        
        
        
        
        
        
        
            
        
        
            
            
                
                    
                
            
                
                    
                
            
                
                    
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
        
        
        <p class="line-summary">This is the first post in the “CPU‑GPU Optimization” series. It lays the kernel‑level foundation for pinned memory, which later posts build on. What is pinned memory?...</p>
        
    </div>
</div>

    

    

    

</div>

    </main>
  </div>

  
  





    




  <footer>
    

    
    





    




    
    <p>Powered by
        <a href="https://gohugo.io/">Hugo</a>
        and
        <a href="https://github.com/tomfran/typo">tomfran/typo</a>
    </p>
    
    
    


  </footer>

  
</body>

<script src="/js/theme-switch.js"></script>
<script defer src="/js/copy-code.js"></script>
</html>

